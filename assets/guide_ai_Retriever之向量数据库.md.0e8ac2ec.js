import{_ as s,o as n,c as a,Q as p}from"./chunks/framework.b6910bb2.js";const o="/vitePress-blob/assets/10.fdf08991.png",m=JSON.parse('{"title":"Retriever 之向量数据库","description":"","frontmatter":{},"headers":[],"relativePath":"guide/ai/Retriever之向量数据库.md","filePath":"guide/ai/Retriever之向量数据库.md","lastUpdated":1736861630000}'),l={name:"guide/ai/Retriever之向量数据库.md"},e=p(`<h1 id="retriever-之向量数据库" tabindex="-1">Retriever 之向量数据库 <a class="header-anchor" href="#retriever-之向量数据库" aria-label="Permalink to &quot;Retriever 之向量数据库&quot;">​</a></h1><p>经过前面的学习，我们知道了如何对 数据进行加载和切割，接下来我们就要学习如何将数据通过 Embedding 算法转化为向量加载到向量数据库中。</p><h2 id="embedding" tabindex="-1">Embedding <a class="header-anchor" href="#embedding" aria-label="Permalink to &quot;Embedding&quot;">​</a></h2><p>这里我们用最简单的词袋（words bag）模型来描述一下最简单的 embedding 过程，让大家更具象化的理解这个。</p><p>简单地说，词袋模型首先将一篇文章拆分成一个个单词，然后将其放入袋子里面。</p><p>例如我们有十篇文章，我们可以将文章拆分成一个个单词，然后统计单词出现的次数</p><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">第一篇文章</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#B392F0;">enson</span><span style="color:#E1E4E8;">: </span><span style="color:#79B8FF;">10</span><span style="color:#E1E4E8;">  </span><span style="color:#B392F0;">cool</span><span style="color:#E1E4E8;">: </span><span style="color:#79B8FF;">5</span><span style="color:#E1E4E8;">  </span><span style="color:#B392F0;">handsome</span><span style="color:#E1E4E8;">: </span><span style="color:#79B8FF;">8</span></span>
<span class="line"></span>
<span class="line"><span style="color:#B392F0;">第二篇文章</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#B392F0;">monkey</span><span style="color:#E1E4E8;">: </span><span style="color:#79B8FF;">8</span><span style="color:#E1E4E8;">  </span><span style="color:#B392F0;">cute</span><span style="color:#E1E4E8;">: </span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">handsome</span><span style="color:#E1E4E8;">: </span><span style="color:#79B8FF;">4</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">第一篇文章</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#6F42C1;">enson</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">  </span><span style="color:#6F42C1;">cool</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">5</span><span style="color:#24292E;">  </span><span style="color:#6F42C1;">handsome</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">8</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6F42C1;">第二篇文章</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#6F42C1;">monkey</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">8</span><span style="color:#24292E;">  </span><span style="color:#6F42C1;">cute</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">2</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">handsome</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">4</span></span></code></pre></div><p>那我们尝试构建一个向量，也就是一个数组，每个位置有一个值，代表每个单词在这个文章中出现的次数</p><p><code>[enson, cool, handsome, monkey, cute]</code></p><p>那每篇文章，都能用一个变量来表示</p><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[</span><span style="color:#79B8FF;">10</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">5</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">8</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">]</span></span>
<span class="line"><span style="color:#E1E4E8;">[</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">8</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">8</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">4</span><span style="color:#E1E4E8;">]</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">5</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">]</span></span></code></pre></div><p>可以用最简单的余弦定理去计算两个向量之间的夹角，以此确定两个向量的距离。 这样，我们就有了通过向量和向量之间的余弦夹角的，来衡量文章之间相似度的能力。</p><p>回到我们 RAG 流程中，我们将切分后的每一个文档块使用 embedding 算法转换成一个向量，存储到向量数据库中（vector store）中。这样，每一个原始数据都有一个对应的向量，可以用来检索。</p><p>在企业开发中，一般会使用厂商提供的 Embedding 服务，例如</p><h2 id="vectorstore" tabindex="-1">VectorStore <a class="header-anchor" href="#vectorstore" aria-label="Permalink to &quot;VectorStore&quot;">​</a></h2><p>Vector store 提供提供的是存储向量和原始文档，并且提供基于向量进行相关性检索的能力。</p><p>因为 js 并不是一个面向后端和机器学习相关的语言，所以原生的 vector store 并不多，大多数还是以支持 python 为主。目前也有像 <a href="https://lancedb.com/" target="_blank" rel="noreferrer">lanceDB</a> 原生支持 js 的，但毕竟是少数。</p><p>我们将使用由 facebook 开源的 <a href="https://github.com/facebookresearch/faiss" target="_blank" rel="noreferrer">faiss</a> 向量数据库，目前有 27.7k star，是向量数据库中非常流行的开源解决方案。选择这个的原因是其可以将向量数据库导出成文件，并且提供了 python 和 nodejs 的处理方式。</p><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;">// 安装 faiss</span></span>
<span class="line"><span style="color:#E1E4E8;">yarn add faiss</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">node</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;">// 安装 faiss</span></span>
<span class="line"><span style="color:#24292E;">yarn add faiss</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">node</span></span></code></pre></div><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;">// https://js.langchain.com/v0.2/docs/integrations/vectorstores/faiss/#create-a-new-index-from-texts</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;dotenv/config&quot;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { FaissStore } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;@langchain/community/vectorstores/faiss&quot;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { TextLoader } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;langchain/document_loaders/fs/text&quot;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { RecursiveCharacterTextSplitter } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;langchain/text_splitter&#39;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { BaiduQianfanEmbeddings } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;@langchain/community/embeddings/baidu_qianfan&quot;</span><span style="color:#E1E4E8;">; </span><span style="color:#6A737D;">// 开通千帆 Embedding 模型, https://cloud.baidu.com/doc/VDB/s/Nltgvlg7k</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">loader</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">new</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">TextLoader</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&#39;./data/kong.txt&#39;</span><span style="color:#E1E4E8;">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">docs</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">await</span><span style="color:#E1E4E8;"> loader.</span><span style="color:#B392F0;">load</span><span style="color:#E1E4E8;">();</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">splitter</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">new</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">RecursiveCharacterTextSplitter</span><span style="color:#E1E4E8;">({</span></span>
<span class="line"><span style="color:#E1E4E8;">    chunkSize: </span><span style="color:#79B8FF;">100</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// 分块的大小</span></span>
<span class="line"><span style="color:#E1E4E8;">    chunkOverlap: </span><span style="color:#79B8FF;">20</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// 块之间的重叠</span></span>
<span class="line"><span style="color:#E1E4E8;">});</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">splitDocs</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">await</span><span style="color:#E1E4E8;"> splitter.</span><span style="color:#B392F0;">splitDocuments</span><span style="color:#E1E4E8;">(docs);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">embedding</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">new</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">BaiduQianfanEmbeddings</span><span style="color:#E1E4E8;">(); </span><span style="color:#6A737D;">// Embedding-V1是基于百度文心大模型技术的文本表示模型，将文本转化为用数值表示的向量形式，用于文本检索、信息推荐、知识挖掘等场景。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">vectorStore</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">await</span><span style="color:#E1E4E8;"> FaissStore.</span><span style="color:#B392F0;">fromDocuments</span><span style="color:#E1E4E8;">(splitDocs, embedding);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">retriever</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> vectorStore.</span><span style="color:#B392F0;">asRetriever</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">); </span><span style="color:#6A737D;">// 获取最相关的俩个文档片段</span></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">res</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">await</span><span style="color:#E1E4E8;"> retriever.</span><span style="color:#B392F0;">invoke</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&quot;茴香豆是做什么用的&quot;</span><span style="color:#E1E4E8;">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">console.</span><span style="color:#B392F0;">log</span><span style="color:#E1E4E8;">(res);</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;">// https://js.langchain.com/v0.2/docs/integrations/vectorstores/faiss/#create-a-new-index-from-texts</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;dotenv/config&quot;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { FaissStore } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;@langchain/community/vectorstores/faiss&quot;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { TextLoader } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;langchain/document_loaders/fs/text&quot;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { RecursiveCharacterTextSplitter } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;langchain/text_splitter&#39;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { BaiduQianfanEmbeddings } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;@langchain/community/embeddings/baidu_qianfan&quot;</span><span style="color:#24292E;">; </span><span style="color:#6A737D;">// 开通千帆 Embedding 模型, https://cloud.baidu.com/doc/VDB/s/Nltgvlg7k</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">loader</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">new</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">TextLoader</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;./data/kong.txt&#39;</span><span style="color:#24292E;">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">docs</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">await</span><span style="color:#24292E;"> loader.</span><span style="color:#6F42C1;">load</span><span style="color:#24292E;">();</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">splitter</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">new</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">RecursiveCharacterTextSplitter</span><span style="color:#24292E;">({</span></span>
<span class="line"><span style="color:#24292E;">    chunkSize: </span><span style="color:#005CC5;">100</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// 分块的大小</span></span>
<span class="line"><span style="color:#24292E;">    chunkOverlap: </span><span style="color:#005CC5;">20</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// 块之间的重叠</span></span>
<span class="line"><span style="color:#24292E;">});</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">splitDocs</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">await</span><span style="color:#24292E;"> splitter.</span><span style="color:#6F42C1;">splitDocuments</span><span style="color:#24292E;">(docs);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">embedding</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">new</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">BaiduQianfanEmbeddings</span><span style="color:#24292E;">(); </span><span style="color:#6A737D;">// Embedding-V1是基于百度文心大模型技术的文本表示模型，将文本转化为用数值表示的向量形式，用于文本检索、信息推荐、知识挖掘等场景。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">vectorStore</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">await</span><span style="color:#24292E;"> FaissStore.</span><span style="color:#6F42C1;">fromDocuments</span><span style="color:#24292E;">(splitDocs, embedding);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">retriever</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> vectorStore.</span><span style="color:#6F42C1;">asRetriever</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">); </span><span style="color:#6A737D;">// 获取最相关的俩个文档片段</span></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">res</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">await</span><span style="color:#24292E;"> retriever.</span><span style="color:#6F42C1;">invoke</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&quot;茴香豆是做什么用的&quot;</span><span style="color:#24292E;">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">console.</span><span style="color:#6F42C1;">log</span><span style="color:#24292E;">(res);</span></span></code></pre></div><p><img src="`+o+'" alt="输出结果"></p>',21),t=[e];function c(r,y,E,i,d,F){return n(),a("div",null,t)}const u=s(l,[["render",c]]);export{m as __pageData,u as default};
