import{_ as s,o as n,c as a,Q as l}from"./chunks/framework.b6910bb2.js";const o="/vitePress-blob/assets/12.f148ecd9.png",p="/vitePress-blob/assets/13.24cbed74.png",v=JSON.parse('{"title":"Retriever 常见的优化方式","description":"","frontmatter":{},"headers":[],"relativePath":"guide/ai/Retriever 常见的优化方式.md","filePath":"guide/ai/Retriever 常见的优化方式.md","lastUpdated":1745055687000}'),e={name:"guide/ai/Retriever 常见的优化方式.md"},r=l(`<h1 id="retriever-常见的优化方式" tabindex="-1">Retriever 常见的优化方式 <a class="header-anchor" href="#retriever-常见的优化方式" aria-label="Permalink to &quot;Retriever 常见的优化方式&quot;">​</a></h1><p>上一节我们通过厂商提供的 Embedding 算法去制作匹配向量，通过 Facebook 提供的 Faiss 作为向量数据库，将数据存储到向量数据库中。</p><p>接下来我们将优化 Retriever 检索数据的方式</p><h2 id="multiqueryretriever" tabindex="-1">MultiQueryRetriever <a class="header-anchor" href="#multiqueryretriever" aria-label="Permalink to &quot;MultiQueryRetriever&quot;">​</a></h2><p>MultiQueryRetriever 思路，或者说其他解决 llm 缺陷的思路基本都是一致的：加入更多 llm。</p><p>而 MultiQueryRetriever 是其中比较简单的一种解决方案，它使用 LLM 去将用户的输入改写成多个不同写法，从不同的角度来表达同一个意思，来克服因为关键词或者细微措词导致检索效果差的问题。</p><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;">// MultiQueryRetriever: </span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;dotenv/config&quot;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { FaissStore } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;@langchain/community/vectorstores/faiss&quot;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { BaiduQianfanEmbeddings } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;@langchain/community/embeddings/baidu_qianfan&quot;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { MultiQueryRetriever } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;langchain/retrievers/multi_query&quot;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { TextLoader } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;langchain/document_loaders/fs/text&quot;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> { RecursiveCharacterTextSplitter } </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;langchain/text_splitter&#39;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> ollama </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;./utils/ollama-llm.mjs&#39;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> ernieTurbo </span><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;./utils/baidu-llm.mjs&#39;</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">loader</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">new</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">TextLoader</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&#39;./data/kong.txt&#39;</span><span style="color:#E1E4E8;">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">docs</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">await</span><span style="color:#E1E4E8;"> loader.</span><span style="color:#B392F0;">load</span><span style="color:#E1E4E8;">();</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">splitter</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">new</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">RecursiveCharacterTextSplitter</span><span style="color:#E1E4E8;">({</span></span>
<span class="line"><span style="color:#E1E4E8;">    chunkSize: </span><span style="color:#79B8FF;">100</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// 分块的大小</span></span>
<span class="line"><span style="color:#E1E4E8;">    chunkOverlap: </span><span style="color:#79B8FF;">20</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// 块之间的重叠</span></span>
<span class="line"><span style="color:#E1E4E8;">});</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">splitDocs</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">await</span><span style="color:#E1E4E8;"> splitter.</span><span style="color:#B392F0;">splitDocuments</span><span style="color:#E1E4E8;">(docs); </span><span style="color:#6A737D;">// 对文章进行切片</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">embedding</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">new</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">BaiduQianfanEmbeddings</span><span style="color:#E1E4E8;">(); </span><span style="color:#6A737D;">// Embedding-V1是基于百度文心大模型技术的文本表示模型，将文本转化为用数值表示的向量形式，用于文本检索、信息推荐、知识挖掘等场景。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">vectorStore</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">await</span><span style="color:#E1E4E8;"> FaissStore.</span><span style="color:#B392F0;">fromDocuments</span><span style="color:#E1E4E8;">(splitDocs, embedding); </span><span style="color:#6A737D;">// 从文档中创建一个向量存储</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">retriever</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> MultiQueryRetriever.</span><span style="color:#B392F0;">fromLLM</span><span style="color:#E1E4E8;">({ </span><span style="color:#6A737D;">// 通过 LLM 去生存不同的检索</span></span>
<span class="line"><span style="color:#E1E4E8;">    llm: ernieTurbo, </span><span style="color:#6A737D;">// 传入的 LLM 模型</span></span>
<span class="line"><span style="color:#E1E4E8;">    retriever: vectorStore.</span><span style="color:#B392F0;">asRetriever</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">), </span><span style="color:#6A737D;">// 向量数据库的 retriever</span></span>
<span class="line"><span style="color:#E1E4E8;">    queryCount: </span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// 生成 3 条不同的描述</span></span>
<span class="line"><span style="color:#E1E4E8;">    verbose: </span><span style="color:#79B8FF;">true</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// 设置为 true 会打印出 chain 内部的详细执行过程方便 debug</span></span>
<span class="line"><span style="color:#E1E4E8;">});</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">res</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">await</span><span style="color:#E1E4E8;"> retriever.</span><span style="color:#B392F0;">invoke</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&quot;茴香豆是做什么用的&quot;</span><span style="color:#E1E4E8;">); </span><span style="color:#6A737D;">// 一共会生成 9 条数据，再做去重</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">console.</span><span style="color:#B392F0;">log</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">\`res\`</span><span style="color:#E1E4E8;">, res);</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;">// MultiQueryRetriever: </span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;dotenv/config&quot;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { FaissStore } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;@langchain/community/vectorstores/faiss&quot;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { BaiduQianfanEmbeddings } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;@langchain/community/embeddings/baidu_qianfan&quot;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { MultiQueryRetriever } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;langchain/retrievers/multi_query&quot;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { TextLoader } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;langchain/document_loaders/fs/text&quot;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> { RecursiveCharacterTextSplitter } </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;langchain/text_splitter&#39;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> ollama </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;./utils/ollama-llm.mjs&#39;</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> ernieTurbo </span><span style="color:#D73A49;">from</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;./utils/baidu-llm.mjs&#39;</span><span style="color:#24292E;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">loader</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">new</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">TextLoader</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;./data/kong.txt&#39;</span><span style="color:#24292E;">);</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">docs</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">await</span><span style="color:#24292E;"> loader.</span><span style="color:#6F42C1;">load</span><span style="color:#24292E;">();</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">splitter</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">new</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">RecursiveCharacterTextSplitter</span><span style="color:#24292E;">({</span></span>
<span class="line"><span style="color:#24292E;">    chunkSize: </span><span style="color:#005CC5;">100</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// 分块的大小</span></span>
<span class="line"><span style="color:#24292E;">    chunkOverlap: </span><span style="color:#005CC5;">20</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// 块之间的重叠</span></span>
<span class="line"><span style="color:#24292E;">});</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">splitDocs</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">await</span><span style="color:#24292E;"> splitter.</span><span style="color:#6F42C1;">splitDocuments</span><span style="color:#24292E;">(docs); </span><span style="color:#6A737D;">// 对文章进行切片</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">embedding</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">new</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">BaiduQianfanEmbeddings</span><span style="color:#24292E;">(); </span><span style="color:#6A737D;">// Embedding-V1是基于百度文心大模型技术的文本表示模型，将文本转化为用数值表示的向量形式，用于文本检索、信息推荐、知识挖掘等场景。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">vectorStore</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">await</span><span style="color:#24292E;"> FaissStore.</span><span style="color:#6F42C1;">fromDocuments</span><span style="color:#24292E;">(splitDocs, embedding); </span><span style="color:#6A737D;">// 从文档中创建一个向量存储</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">retriever</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> MultiQueryRetriever.</span><span style="color:#6F42C1;">fromLLM</span><span style="color:#24292E;">({ </span><span style="color:#6A737D;">// 通过 LLM 去生存不同的检索</span></span>
<span class="line"><span style="color:#24292E;">    llm: ernieTurbo, </span><span style="color:#6A737D;">// 传入的 LLM 模型</span></span>
<span class="line"><span style="color:#24292E;">    retriever: vectorStore.</span><span style="color:#6F42C1;">asRetriever</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">), </span><span style="color:#6A737D;">// 向量数据库的 retriever</span></span>
<span class="line"><span style="color:#24292E;">    queryCount: </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// 生成 3 条不同的描述</span></span>
<span class="line"><span style="color:#24292E;">    verbose: </span><span style="color:#005CC5;">true</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// 设置为 true 会打印出 chain 内部的详细执行过程方便 debug</span></span>
<span class="line"><span style="color:#24292E;">});</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">res</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">await</span><span style="color:#24292E;"> retriever.</span><span style="color:#6F42C1;">invoke</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&quot;茴香豆是做什么用的&quot;</span><span style="color:#24292E;">); </span><span style="color:#6A737D;">// 一共会生成 9 条数据，再做去重</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">console.</span><span style="color:#6F42C1;">log</span><span style="color:#24292E;">(</span><span style="color:#032F62;">\`res\`</span><span style="color:#24292E;">, res);</span></span></code></pre></div><p>执行上面的代码我们可以看到，通过 LLM 目前，可以将我们的描述生成 3 条不同的描述，避免语意偏差。</p><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">茴香豆的主要用途是什么？</span></span>
<span class="line"><span style="color:#E1E4E8;">茴香豆通常用于哪些场合或文化中？</span></span>
<span class="line"><span style="color:#E1E4E8;">茴香豆在烹饪中有什么作用？</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">茴香豆的主要用途是什么？</span></span>
<span class="line"><span style="color:#24292E;">茴香豆通常用于哪些场合或文化中？</span></span>
<span class="line"><span style="color:#24292E;">茴香豆在烹饪中有什么作用？</span></span></code></pre></div><p>因为用户的原始输入是 <code>茴香豆是做什么用的</code>，这是一个非常模糊和有歧义性的问题，作为写这个问题的用户，他可能了解想要的答案是 “茴香豆是下酒用的”，但因为自然语言的特点，这是有歧义的的。</p><p>MultiQueryRetriever 的意义就是，找出这句话所有可能的意义，然后用这些可能的意义去检索，避免因为歧义导致检索错误。</p><h2 id="contextualcompressionretriever" tabindex="-1">ContextualCompressionRetriever <a class="header-anchor" href="#contextualcompressionretriever" aria-label="Permalink to &quot;ContextualCompressionRetriever&quot;">​</a></h2><p>Retriever 另一个问题是，如果我们设置了 K 值（每次检索返回的文档数量）较小，那么返回的结果可能并不是最佳的效果，就想搜索引擎第一条结果并不一定是问题最高质量的结果一样。</p><p>而如果 K 值设置过大，可能返回的结果会有很多，撑爆了 LLM 的上下文大小。</p><p>因此，我们可以通过 <code>ContextualCompressionRetriever</code> 通过 LLM 去压缩检索结果，然后再返回给用户。</p><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">model</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">new</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">ChatOpenAI</span><span style="color:#E1E4E8;">();</span></span>
<span class="line"><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">compressor</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> LLMChainExtractor.</span><span style="color:#B392F0;">fromLLM</span><span style="color:#E1E4E8;">(model);</span></span>
<span class="line"><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">retriever</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">new</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">ContextualCompressionRetriever</span><span style="color:#E1E4E8;">({</span></span>
<span class="line"><span style="color:#E1E4E8;">    baseCompressor: compressor,</span></span>
<span class="line"><span style="color:#E1E4E8;">    baseRetriever: vectorstore.</span><span style="color:#B392F0;">asRetriever</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">),</span></span>
<span class="line"><span style="color:#E1E4E8;"> });</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">model</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">new</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">ChatOpenAI</span><span style="color:#24292E;">();</span></span>
<span class="line"><span style="color:#24292E;"> </span><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">compressor</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LLMChainExtractor.</span><span style="color:#6F42C1;">fromLLM</span><span style="color:#24292E;">(model);</span></span>
<span class="line"><span style="color:#24292E;"> </span><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">retriever</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">new</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">ContextualCompressionRetriever</span><span style="color:#24292E;">({</span></span>
<span class="line"><span style="color:#24292E;">    baseCompressor: compressor,</span></span>
<span class="line"><span style="color:#24292E;">    baseRetriever: vectorstore.</span><span style="color:#6F42C1;">asRetriever</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">),</span></span>
<span class="line"><span style="color:#24292E;"> });</span></span></code></pre></div><p><img src="`+o+`" alt="输出结果"></p><p>通过结果可以看到，通过 LLM 去压缩检索结果，然后再返回给用户。</p><h2 id="scorethresholdretriever" tabindex="-1">ScoreThresholdRetriever <a class="header-anchor" href="#scorethresholdretriever" aria-label="Permalink to &quot;ScoreThresholdRetriever&quot;">​</a></h2><p>前面我们提到了，K 值的设置可能会导致检索结果不准确，不同的数据中 K 值不一定是固定的，而通过 ScoreThresholdRetriever 可以动态调整 K 值。</p><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">const</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">retriever</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> ScoreThresholdRetriever.</span><span style="color:#B392F0;">fromVectorStore</span><span style="color:#E1E4E8;">(vectorstore, {</span></span>
<span class="line"><span style="color:#E1E4E8;">    minSimilarityScore: </span><span style="color:#79B8FF;">0.4</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// 相似度</span></span>
<span class="line"><span style="color:#E1E4E8;">    maxK: </span><span style="color:#79B8FF;">5</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// 最大 K 值</span></span>
<span class="line"><span style="color:#E1E4E8;">    kIncrement: </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#6A737D;">// K 值每次增加的步长</span></span>
<span class="line"><span style="color:#E1E4E8;">});</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">const</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">retriever</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> ScoreThresholdRetriever.</span><span style="color:#6F42C1;">fromVectorStore</span><span style="color:#24292E;">(vectorstore, {</span></span>
<span class="line"><span style="color:#24292E;">    minSimilarityScore: </span><span style="color:#005CC5;">0.4</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// 相似度</span></span>
<span class="line"><span style="color:#24292E;">    maxK: </span><span style="color:#005CC5;">5</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// 最大 K 值</span></span>
<span class="line"><span style="color:#24292E;">    kIncrement: </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#6A737D;">// K 值每次增加的步长</span></span>
<span class="line"><span style="color:#24292E;">});</span></span></code></pre></div><p><img src="`+p+'" alt="输出结果"></p><h1 id="参考文章" tabindex="-1">参考文章 <a class="header-anchor" href="#参考文章" aria-label="Permalink to &quot;参考文章&quot;">​</a></h1><ul><li><a href="https://js.langchain.com/v0.1/docs/modules/data_connection/retrievers/similarity-score-threshold-retriever/#usage" target="_blank" rel="noreferrer">https://js.langchain.com/v0.1/docs/modules/data_connection/retrievers/similarity-score-threshold-retriever/#usage</a></li><li><a href="https://js.langchain.com/v0.1/docs/modules/data_connection/retrievers/contextual_compression/" target="_blank" rel="noreferrer">https://js.langchain.com/v0.1/docs/modules/data_connection/retrievers/contextual_compression/</a></li></ul>',24),t=[r];function c(E,y,i,d,F,u){return n(),a("div",null,t)}const h=s(e,[["render",c]]);export{v as __pageData,h as default};
